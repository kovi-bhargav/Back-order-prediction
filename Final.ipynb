{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Final.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdvF-ca0im7J"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense , BatchNormalization , LeakyReLU\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint ,TensorBoard\n",
        "import datetime \n",
        "from pickle import load\n",
        "import pdb\n",
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VEug3ITZj-Ky",
        "outputId": "d00d0cef-75a0-457c-a29c-1efca7ad4e6d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqqBj0yTim7P"
      },
      "source": [
        "def final_fun_1(X) :\n",
        "    ''' Takes pandas data frame as input and predict if the order is Back order or not'''\n",
        "    impute_leadtime = np.load('/content/drive/MyDrive/Colab Notebooks/Assignments/Self Case study -1/impute_leadtime.npy')\n",
        "    X['lead_time'] = X['lead_time'].fillna(impute_leadtime)  #1st preprocessing\n",
        "    #Replacing the boolean columns which has Yes with 1 and No with 0 \n",
        "    for col in ['potential_issue','deck_risk', 'oe_constraint','ppap_risk', 'stop_auto_buy', 'rev_stop']:\n",
        "        X[col] = X[col].map({'Yes': 1 , 'No' : 0})  \n",
        "        \n",
        "    if 'sku' in X.columns :\n",
        "        X = X.drop(columns=['sku'])\n",
        "    if 'went_on_backorder' in X.columns :\n",
        "        X = X.drop(columns=['went_on_backorder'])\n",
        "        \n",
        "# The Custom nine fields     \n",
        "    X['net_quantity'] = X.apply(lambda row: row.national_inv +  row.in_transit_qty , axis = 1)\n",
        "    X['safe_quantity'] = X.apply(lambda row: row.net_quantity -  row.min_bank , axis = 1)\n",
        "    X['safe_quantity_pos'] = np.where(X['safe_quantity'] >= 0, 1, 0)\n",
        "    X['max_fore_cast_1_month'] = X.apply(lambda row: max( (row.forecast_9_month - row.forecast_6_month) /3, (row.forecast_6_month - row.forecast_3_month) /3 ) , axis = 1)\n",
        "    X['min_fore_cast_1_month'] = X.apply(lambda row: min( (row.forecast_9_month - row.forecast_6_month) /3, (row.forecast_6_month - row.forecast_3_month) /3 ) , axis = 1)\n",
        "    X['safe_max_diff'] = X.apply(lambda row: row.safe_quantity - row.max_fore_cast_1_month, axis = 1)\n",
        "    X['safe_min_diff'] = X.apply(lambda row: row.safe_quantity - row.min_fore_cast_1_month, axis = 1)\n",
        "    X['safe_max_diff_pos'] = np.where(X['safe_max_diff'] >= 0, 1, 0)\n",
        "    X['safe_min_diff_pos'] = np.where(X['safe_min_diff'] >= 0, 1, 0) \n",
        "    \n",
        "    scaled_X = X.copy(deep = True)\n",
        "    scaler = load((open('/content/drive/MyDrive/Colab Notebooks/Assignments/Self Case study -1/scaler_new.pkl','rb')))\n",
        "    col = ['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month', 'forecast_6_month', 'forecast_9_month', 'sales_1_month', 'sales_3_month', 'sales_6_month', 'sales_9_month', 'min_bank', 'pieces_past_due', 'perf_6_month_avg', 'perf_12_month_avg', 'local_bo_qty', 'net_quantity', 'safe_quantity', 'max_fore_cast_1_month', 'min_fore_cast_1_month', 'safe_max_diff', 'safe_min_diff']\n",
        "    features = scaled_X[col]\n",
        "    features = scaler.transform(features.values)\n",
        "    scaled_X[col] = features   \n",
        "    #auto encoder features \n",
        "    tf.keras.backend.clear_session()\n",
        "    # Building the Input Layer\n",
        "    input_layer = Input(shape =(30,))\n",
        "\n",
        "    # Building Encoder layer\n",
        "    encoded = Dense(25)(input_layer)\n",
        "    encoded = BatchNormalization()(encoded)\n",
        "    encoded = LeakyReLU()(encoded)\n",
        "\n",
        "    encoded = Dense(20)(encoded)\n",
        "    encoded = BatchNormalization()(encoded)\n",
        "    encoded = LeakyReLU()(encoded)\n",
        "\n",
        "    encoded = Dense(15)(encoded)\n",
        "    encoded = BatchNormalization()(encoded)\n",
        "    encoded = LeakyReLU()(encoded)\n",
        "\n",
        "    encoded = Dense(10)(encoded)\n",
        "    encoded = BatchNormalization()(encoded)\n",
        "    encoded = LeakyReLU()(encoded)\n",
        "\n",
        "    # Building Decoder layer\n",
        "    decoded = Dense(15)(encoded)\n",
        "    decoded = BatchNormalization()(decoded)\n",
        "    decoded = LeakyReLU()(decoded)\n",
        "\n",
        "    decoded = Dense(20)(decoded)\n",
        "    decoded = BatchNormalization()(decoded)\n",
        "    decoded = LeakyReLU()(decoded)\n",
        "\n",
        "    decoded = Dense(25)(decoded)\n",
        "    decoded = BatchNormalization()(decoded)\n",
        "    decoded = LeakyReLU()(decoded)\n",
        "\n",
        "    # Building Output Layer\n",
        "    output_layer = Dense(30, activation ='relu')(decoded)\n",
        "\n",
        "    autoencoder = Model(input_layer, output_layer)\n",
        "    autoencoder.load_weights('/content/drive/MyDrive/Colab Notebooks/Assignments/Self Case study -1/autoencoder_save/weights.hdf5') \n",
        "\n",
        "    encode = Sequential()\n",
        "    encode.add(autoencoder.layers[0])\n",
        "    encode.add(autoencoder.layers[1])\n",
        "    encode.add(autoencoder.layers[2])\n",
        "    encode.add(autoencoder.layers[3])\n",
        "    encode.add(autoencoder.layers[4])\n",
        "    encode.add(autoencoder.layers[5])\n",
        "    encode.add(autoencoder.layers[6])\n",
        "    encode.add(autoencoder.layers[7])\n",
        "    encode.add(autoencoder.layers[8])\n",
        "    encode.add(autoencoder.layers[9])\n",
        "    encode.add(autoencoder.layers[10])\n",
        "    encode.add(autoencoder.layers[11])\n",
        "    encode.add(autoencoder.layers[12])    \n",
        "    \n",
        "    auto_encode = encode.predict(scaled_X)\n",
        "    auto_encode_columns = ['auto_encode_'+str(i) for i in range(1,11)]\n",
        "    auto_encode = pd.DataFrame(data = auto_encode , columns = auto_encode_columns )\n",
        "\n",
        "    auto_encode = pd.concat([X.reset_index(drop=True), auto_encode.reset_index(drop=True)], axis=1) \n",
        "    \n",
        "    final_model = load(open('/content/drive/MyDrive/Colab Notebooks/Assignments/Self Case study -1/final_rf_model.sav', 'rb'))\n",
        "    return final_model.predict(auto_encode)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo0oXdDzim7R"
      },
      "source": [
        "test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Assignments/Self Case study -1/Kaggle_Test_Dataset_v2.csv')\n",
        "test_data = test_data.iloc[:-1,:] #last row is invalid\n",
        "# test_data = test_data.drop(columns=['Unnamed: 0'])  \n",
        "final_fun_1(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_HeLT0O0GR2"
      },
      "source": [
        "def final_fun_2(X,y) :\n",
        "    '''Takes X and y as input and return the recall value for backorder'''\n",
        "    predict_y = final_fun_1(X)\n",
        "    return(round(recall_score(y,predict_y),3))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tu2D7pSv_gcO",
        "outputId": "27004c2f-ccfc-4736-9588-77f626f4b5ed"
      },
      "source": [
        "test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Assignments/Self Case study -1/Kaggle_Test_Dataset_v2.csv')\n",
        "test_data = test_data.iloc[:-1,:] #last row is invalid\n",
        "test_data['went_on_backorder'] = test_data['went_on_backorder'].map({'Yes': 1 , 'No' : 0}) \n",
        "print(final_fun_2(test_data,test_data.went_on_backorder))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.844\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}